{"noir_version":"1.0.0-beta.18+99bb8b5cf33d7669adbdef096b12d80f30b4c0c9","hash":"11607262964700411967","abi":{"parameters":[{"name":"verification_key","type":{"kind":"array","length":115,"type":{"kind":"field"}},"visibility":"private"},{"name":"vkey_hash","type":{"kind":"field"},"visibility":"private"},{"name":"proof_left","type":{"kind":"array","length":508,"type":{"kind":"field"}},"visibility":"private"},{"name":"proof_right","type":{"kind":"struct","path":"std::option::Option","fields":[{"name":"_is_some","type":{"kind":"boolean"}},{"name":"_value","type":{"kind":"array","length":508,"type":{"kind":"field"}}}]},"visibility":"private"},{"name":"public_inputs_left","type":{"kind":"array","length":6,"type":{"kind":"field"}},"visibility":"private"},{"name":"public_inputs_right","type":{"kind":"struct","path":"std::option::Option","fields":[{"name":"_is_some","type":{"kind":"boolean"}},{"name":"_value","type":{"kind":"array","length":6,"type":{"kind":"field"}}}]},"visibility":"private"},{"name":"zero_leaf_hint","type":{"kind":"struct","path":"std::option::Option","fields":[{"name":"_is_some","type":{"kind":"boolean"}},{"name":"_value","type":{"kind":"field"}}]},"visibility":"private"},{"name":"leaf_vkey_hash","type":{"kind":"field"},"visibility":"private"},{"name":"summary_vkey_hash","type":{"kind":"field"},"visibility":"private"}],"return_type":{"abi_type":{"kind":"tuple","fields":[{"kind":"field"},{"kind":"field"},{"kind":"field"},{"kind":"field"},{"kind":"field"},{"kind":"field"}]},"visibility":"public"},"error_types":{"1998584279744703196":{"error_kind":"string","string":"attempt to subtract with overflow"},"5017203466037832267":{"error_kind":"string","string":"vkey hash inconsistent with summary_vkey_hash"},"9462868261386484342":{"error_kind":"string","string":"price feed address mismatch"},"10870757623219956079":{"error_kind":"string","string":"lot hash chain broken: left remaining != right initial"},"14990209321349310352":{"error_kind":"string","string":"attempt to add with overflow"}}},"bytecode":"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","debug_symbols":"tZjdbuM4DEbfxde+EH8kivMqi0WRtukgQJAWmWSARTHvvlLzSW4WsNHVYK4OE9cHokxSjd+n5/3j9fvD4fTy+mP69tf79Hg+HI+H7w/H16fd5fB6Kt++/5qn9vHhct7vy1fTp+vlrrfdeX+6TN9O1+Nxnn7ujtePP/rxtjt98LI7l6thnvan58IifDkc9zX6NS93h/VbKXjE3UQmXRDpzkDrBs5KMLDnuBj4zsDrBikKGESSdQPzl7NgsZYFx7yWxabBvBkkhBGDcN9J0TRksNwN7iMG5Z6FxqEsdFmDjq0hUzdk1dWK2lBYEhjMlo3Ur5dDjqktwWW1HIh/u6pJ/mhZe+Keh9nIw3BvBcGBdMDAQUM3xDhkyK0gmIKMGEpDdYOOFCVz6PvArL9r0KEsJLchxcojQ4qjthHDMa2OGJY/11p3RU00kIREbs0pMY7MydJMrS3E1tfAtrENllpNWqalqknvT07Om4lAobSkUZrk3uAbz9OobQWbhFWHbHW4WXuiZM7rjo0j3HtZ+afD8/8YKHCfVCHFdcdGaWp5EG1Dc1wyIf/6ZnhvUnJe34yt4rLc9lPy0D8CkmkxDPV5MdBiGJl3smyEONuQoc998bE2LUfvYhhZgwbpFRHSyD4okfYmlZG5r7xUJQsPraFXlPLQ+VfW0LPgofNPy6hpBvnPGv4un3ZPh/PdT5NJylObJ60/C+Yp1sk4T6mev/Nk9Qicp3yD1+NsnijUQ6mQQAYFLKo6+Km46mlOCTQwg14H/DxxAAnk2puFAioYwQQamEG/UQJIIHxSfaVORcEIJtDADPqNGkACGYRP4VP4FD6tvtKbmkG/MQaQarEXMiigghFMoIEZ9BtTAOFL1VceXhJQwQgm0MAM+o0WQALhM/gMPoPPqq+UhxmYQb8xB5BABgVUMILwZfgyfBk+h8/hc/gcPofP4XP4HD6Hz+GjEFpALeAWSAu0BdUqNUgtsBbkFlRzrfDaKreAWsAtkBZoC2ILUgusBdVcZ9rP3fmwezzu8U7h5Xp6+vSK4fLPW7vSXkK8nV+f9s/X8772/Me1MgX+BQ==","file_map":{"19":{"source":"// Exposed only for usage in `std::meta`\npub(crate) mod poseidon2;\n\nuse crate::default::Default;\nuse crate::embedded_curve_ops::{\n    EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_array_return,\n};\nuse crate::meta::derive_via;\n\n#[foreign(sha256_compression)]\n// docs:start:sha256_compression\npub fn sha256_compression(input: [u32; 16], state: [u32; 8]) -> [u32; 8] {}\n// docs:end:sha256_compression\n\n#[foreign(keccakf1600)]\n// docs:start:keccakf1600\npub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {}\n// docs:end:keccakf1600\n\npub mod keccak {\n    #[deprecated(\"This function has been moved to std::hash::keccakf1600\")]\n    pub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {\n        super::keccakf1600(input)\n    }\n}\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{\n    if crate::runtime::is_unconstrained() {\n        // Temporary measure while Barretenberg is main proving system.\n        // Please open an issue if you're working on another proving system and running into problems due to this.\n        crate::static_assert(\n            N <= 1024,\n            \"Barretenberg cannot prove blake3 hashes with inputs larger than 1024 bytes\",\n        );\n    }\n    __blake3(input)\n}\n\n#[foreign(blake3)]\nfn __blake3<let N: u32>(input: [u8; N]) -> [u8; 32] {}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\n#[inline_always]\npub fn pedersen_commitment_with_separator<let N: u32>(\n    input: [Field; N],\n    separator: u32,\n) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator(input, 0)\n}\n\n#[no_predicates]\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: [EmbeddedCurveScalar; N + 1] = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N + 1];\n    let mut generators: [EmbeddedCurvePoint; N + 1] =\n        [EmbeddedCurvePoint::point_at_infinity(); N + 1];\n    let domain_generators: [EmbeddedCurvePoint; N] =\n        derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n\n    for i in 0..N {\n        scalars[i] = from_field_unsafe(input[i]);\n        generators[i] = domain_generators[i];\n    }\n    scalars[N] = EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field };\n\n    let length_generator: [EmbeddedCurvePoint; 1] =\n        derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    generators[N] = length_generator[0];\n    multi_scalar_mul_array_return(generators, scalars, true)[0].x\n}\n\n#[field(bn254)]\n#[inline_always]\npub fn derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Decompose the input 'bn254 scalar' into two 128 bits limbs.\n// It is called 'unsafe' because it does not assert the limbs are 128 bits\n// Assuming the limbs are 128 bits:\n// Assert the decomposition does not overflow the field size.\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    // Safety: xlo and xhi decomposition is checked below\n    let (xlo, xhi) = unsafe { crate::field::bn254::decompose_hint(scalar) };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    // Check that the decomposition does not overflow the field size\n    let (a, b) = if xhi == crate::field::bn254::PHI {\n        (xlo, crate::field::bn254::PLO)\n    } else {\n        (xhi, crate::field::bn254::PHI)\n    };\n    crate::field::bn254::assert_lt(a, b);\n\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn poseidon2_permutation<let N: u32>(input: [Field; N], state_len: u32) -> [Field; N] {\n    assert_eq(input.len(), state_len);\n    poseidon2_permutation_internal(input)\n}\n\n#[foreign(poseidon2_permutation)]\nfn poseidon2_permutation_internal<let N: u32>(input: [Field; N]) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: TypeDefinition) -> Quoted {\n    let name = quote { $crate::hash::Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: $crate::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(\n        s,\n        name,\n        signature,\n        for_each_field,\n        quote {},\n        |fields| fields,\n    )\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher {\n    type H: Hasher;\n\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    type H = H;\n\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u128 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u8 as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u16 as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u32 as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u64 as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H)\n    where\n        H: Hasher,\n    {}\n}\n\nimpl<T, let N: u32> Hash for [T; N]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B)\nwhere\n    A: Hash,\n    B: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n    E: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1),\n        0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1),\n        EmbeddedCurvePoint {\n            x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n            y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n            is_infinite: false,\n        },\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2),\n        0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2),\n        EmbeddedCurvePoint {\n            x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n            y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3),\n        0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3),\n        EmbeddedCurvePoint {\n            x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n            y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4),\n        0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4),\n        EmbeddedCurvePoint {\n            x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n            y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5),\n        0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5),\n        EmbeddedCurvePoint {\n            x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n            y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6),\n        0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6),\n        EmbeddedCurvePoint {\n            x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n            y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        EmbeddedCurvePoint {\n            x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n            y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        EmbeddedCurvePoint {\n            x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n            y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        EmbeddedCurvePoint {\n            x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n            y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        EmbeddedCurvePoint {\n            x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n            y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n            is_infinite: false,\n        },\n    );\n}\n","path":"std/hash/mod.nr"},"22":{"source":"pub mod hash;\npub mod aes128;\npub mod array;\npub mod vector;\npub mod ecdsa_secp256k1;\npub mod ecdsa_secp256r1;\npub mod embedded_curve_ops;\npub mod field;\npub mod collections;\npub mod compat;\npub mod convert;\npub mod option;\npub mod string;\npub mod test;\npub mod cmp;\npub mod ops;\npub mod default;\npub mod prelude;\npub mod runtime;\npub mod meta;\npub mod append;\npub mod mem;\npub mod panic;\npub mod hint;\n\nmod primitive_docs;\n\nuse convert::AsPrimitive;\n\n// Oracle calls are required to be wrapped in an unconstrained function\n// Thus, the only argument to the `println` oracle is expected to always be an ident\n#[oracle(print)]\nunconstrained fn print_oracle<T>(with_newline: bool, input: T) {}\n\nunconstrained fn print_unconstrained<T>(with_newline: bool, input: T) {\n    print_oracle(with_newline, input);\n}\n\npub fn println<T>(input: T) {\n    // Safety: a print statement cannot be constrained\n    unsafe {\n        print_unconstrained(true, input);\n    }\n}\n\npub fn print<T>(input: T) {\n    // Safety: a print statement cannot be constrained\n    unsafe {\n        print_unconstrained(false, input);\n    }\n}\n\n/// Asserts the validity of the provided proof and public inputs against the provided verification key and hash.\n///\n/// The ACVM cannot determine whether the provided proof is valid during execution as this requires knowledge of\n/// the backend against which the program is being proven. However if an invalid proof if submitted, the program may\n/// fail to prove or the backend may generate a proof which will subsequently fail to verify.\n///\n/// # Important Note\n///\n/// If you are not developing your own backend such as [Barretenberg](https://github.com/AztecProtocol/barretenberg)\n/// you probably shouldn't need to interact with this function directly. It's easier and safer to use a verification\n/// library which is published by the developers of the backend which will document or enforce any safety requirements.\n///\n/// If you use this directly, you're liable to introduce underconstrainedness bugs and *your circuit will be insecure*.\n///\n/// # Arguments\n/// - verification_key: The verification key of the circuit to be verified.\n/// - proof: The proof to be verified.\n/// - public_inputs: The public inputs associated with `proof`\n/// - key_hash: The hash of `verification_key` of the form expected by the backend.\n/// - proof_type: An identifier for the proving scheme used to generate the proof to be verified. This allows\n///               for a single backend to support verifying multiple proving schemes.\n///\n/// # Constraining `key_hash`\n///\n/// The Noir compiler does not by itself constrain that `key_hash` is a valid hash of `verification_key`.\n/// This is because different backends may differ in how they hash their verification keys.\n/// It is then the responsibility of either the noir developer (by explicitly hashing the verification key\n/// in the correct manner) or by the proving system itself internally asserting the correctness of `key_hash`.\npub fn verify_proof_with_type<let N: u32, let M: u32, let K: u32>(\n    verification_key: [Field; N],\n    proof: [Field; M],\n    public_inputs: [Field; K],\n    key_hash: Field,\n    proof_type: u32,\n) {\n    if !crate::runtime::is_unconstrained() {\n        crate::assert_constant(proof_type);\n    }\n    verify_proof_internal(verification_key, proof, public_inputs, key_hash, proof_type);\n}\n\n#[foreign(recursive_aggregation)]\nfn verify_proof_internal<let N: u32, let M: u32, let K: u32>(\n    verification_key: [Field; N],\n    proof: [Field; M],\n    public_inputs: [Field; K],\n    key_hash: Field,\n    proof_type: u32,\n) {}\n\n// Asserts that the given value is known at compile-time.\n// Useful for debugging for-loop bounds.\n#[builtin(assert_constant)]\npub fn assert_constant<T>(x: T) {}\n\n// Asserts that the given value is both true and known at compile-time.\n// The message can be a string, a format string, or any value, as long as it is known at compile-time\n#[builtin(static_assert)]\npub fn static_assert<T>(predicate: bool, message: T) {}\n\n#[deprecated(\"wrapping operations should be done with the Wrapping traits. E.g: x.wrapping_add(y)\")]\npub fn wrapping_add<T>(x: T, y: T) -> T\nwhere\n    T: AsPrimitive<Field>,\n    Field: AsPrimitive<T>,\n{\n    AsPrimitive::as_(x.as_() + y.as_())\n}\n#[deprecated(\"wrapping operations should be done with the Wrapping traits. E.g: x.wrapping_sub(y)\")]\npub fn wrapping_sub<T>(x: T, y: T) -> T\nwhere\n    T: AsPrimitive<Field>,\n    Field: AsPrimitive<T>,\n{\n    //340282366920938463463374607431768211456 is 2^128, it is used to avoid underflow\n    AsPrimitive::as_(x.as_() + 340282366920938463463374607431768211456 - y.as_())\n}\n#[deprecated(\"wrapping operations should be done with the Wrapping traits. E.g: x.wrapping_mul(y)\")]\npub fn wrapping_mul<T>(x: T, y: T) -> T\nwhere\n    T: AsPrimitive<Field>,\n    Field: AsPrimitive<T>,\n{\n    AsPrimitive::as_(x.as_() * y.as_())\n}\n\n#[builtin(as_witness)]\npub fn as_witness(x: Field) {}\n","path":"std/lib.nr"},"42":{"source":"use crate::cmp::{Eq, Ord, Ordering};\nuse crate::default::Default;\nuse crate::hash::{Hash, Hasher};\n\npub struct Option<T> {\n    _is_some: bool,\n    _value: T,\n}\n\nimpl<T> Option<T> {\n    /// Constructs a None value\n    pub fn none() -> Self {\n        Self { _is_some: false, _value: crate::mem::zeroed() }\n    }\n\n    /// Constructs a Some wrapper around the given value\n    pub fn some(_value: T) -> Self {\n        Self { _is_some: true, _value }\n    }\n\n    /// True if this Option is None\n    pub fn is_none(self) -> bool {\n        !self._is_some\n    }\n\n    /// True if this Option is Some\n    pub fn is_some(self) -> bool {\n        self._is_some\n    }\n\n    /// Asserts `self.is_some()` and returns the wrapped value.\n    pub fn unwrap(self) -> T {\n        assert(self._is_some);\n        self._value\n    }\n\n    /// Returns the inner value without asserting `self.is_some()`\n    /// Note that if `self` is `None`, there is no guarantee what value will be returned,\n    /// only that it will be of type `T`.\n    pub fn unwrap_unchecked(self) -> T {\n        self._value\n    }\n\n    /// Returns the wrapped value if `self.is_some()`. Otherwise, returns the given default value.\n    pub fn unwrap_or(self, default: T) -> T {\n        if self._is_some {\n            self._value\n        } else {\n            default\n        }\n    }\n\n    /// Returns the wrapped value if `self.is_some()`. Otherwise, calls the given function to return\n    /// a default value.\n    pub fn unwrap_or_else<Env>(self, default: fn[Env]() -> T) -> T {\n        if self._is_some {\n            self._value\n        } else {\n            default()\n        }\n    }\n\n    /// Asserts `self.is_some()` with a provided custom message and returns the contained `Some` value\n    pub fn expect<let N: u32, MessageTypes>(self, message: fmtstr<N, MessageTypes>) -> T {\n        assert(self.is_some(), message);\n        self._value\n    }\n\n    /// If self is `Some(x)`, this returns `Some(f(x))`. Otherwise, this returns `None`.\n    pub fn map<U, Env>(self, f: fn[Env](T) -> U) -> Option<U> {\n        if self._is_some {\n            Option::some(f(self._value))\n        } else {\n            Option::none()\n        }\n    }\n\n    /// If self is `Some(x)`, this returns `f(x)`. Otherwise, this returns the given default value.\n    pub fn map_or<U, Env>(self, default: U, f: fn[Env](T) -> U) -> U {\n        if self._is_some {\n            f(self._value)\n        } else {\n            default\n        }\n    }\n\n    /// If self is `Some(x)`, this returns `f(x)`. Otherwise, this returns `default()`.\n    pub fn map_or_else<U, Env1, Env2>(self, default: fn[Env1]() -> U, f: fn[Env2](T) -> U) -> U {\n        if self._is_some {\n            f(self._value)\n        } else {\n            default()\n        }\n    }\n\n    /// Returns None if self is None. Otherwise, this returns `other`.\n    pub fn and(self, other: Self) -> Self {\n        if self.is_none() {\n            Option::none()\n        } else {\n            other\n        }\n    }\n\n    /// If self is None, this returns None. Otherwise, this calls the given function\n    /// with the Some value contained within self, and returns the result of that call.\n    ///\n    /// In some languages this function is called `flat_map` or `bind`.\n    pub fn and_then<U, Env>(self, f: fn[Env](T) -> Option<U>) -> Option<U> {\n        if self._is_some {\n            f(self._value)\n        } else {\n            Option::none()\n        }\n    }\n\n    /// If self is Some, return self. Otherwise, return `other`.\n    pub fn or(self, other: Self) -> Self {\n        if self._is_some {\n            self\n        } else {\n            other\n        }\n    }\n\n    /// If self is Some, return self. Otherwise, return `default()`.\n    pub fn or_else<Env>(self, default: fn[Env]() -> Self) -> Self {\n        if self._is_some {\n            self\n        } else {\n            default()\n        }\n    }\n\n    // If only one of the two Options is Some, return that option.\n    // Otherwise, if both options are Some or both are None, None is returned.\n    pub fn xor(self, other: Self) -> Self {\n        if self._is_some {\n            if other._is_some {\n                Option::none()\n            } else {\n                self\n            }\n        } else if other._is_some {\n            other\n        } else {\n            Option::none()\n        }\n    }\n\n    /// Returns `Some(x)` if self is `Some(x)` and `predicate(x)` is true.\n    /// Otherwise, this returns `None`\n    pub fn filter<Env>(self, predicate: fn[Env](T) -> bool) -> Self {\n        if self._is_some {\n            if predicate(self._value) {\n                self\n            } else {\n                Option::none()\n            }\n        } else {\n            Option::none()\n        }\n    }\n\n    /// Flattens an Option<Option<T>> into a Option<T>.\n    /// This returns None if the outer Option is None. Otherwise, this returns the inner Option.\n    pub fn flatten(option: Option<Option<T>>) -> Option<T> {\n        if option._is_some {\n            option._value\n        } else {\n            Option::none()\n        }\n    }\n}\n\nimpl<T> Default for Option<T> {\n    fn default() -> Self {\n        Option::none()\n    }\n}\n\nimpl<T> Eq for Option<T>\nwhere\n    T: Eq,\n{\n    fn eq(self, other: Self) -> bool {\n        if self._is_some == other._is_some {\n            if self._is_some {\n                self._value == other._value\n            } else {\n                true\n            }\n        } else {\n            false\n        }\n    }\n}\n\nimpl<T> Hash for Option<T>\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self._is_some.hash(state);\n        if self._is_some {\n            self._value.hash(state);\n        }\n    }\n}\n\n// For this impl we're declaring Option::none < Option::some\nimpl<T> Ord for Option<T>\nwhere\n    T: Ord,\n{\n    fn cmp(self, other: Self) -> Ordering {\n        if self._is_some {\n            if other._is_some {\n                self._value.cmp(other._value)\n            } else {\n                Ordering::greater()\n            }\n        } else if other._is_some {\n            Ordering::less()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n","path":"std/option.nr"},"51":{"source":"use bb_proof_verification::{UltraHonkZKProof, UltraHonkVerificationKey, verify_honk_proof};\nuse dep::protocol_types::hash::poseidon2_hash;\n\n/// Public inputs per child proof (6 Fields):\n///   [0] leaf_or_root          - leaf hash (individual) or merkle root (summary)\n///   [1] pnl                   - absolute PnL value\n///   [2] pnl_is_negative       - 0 = gain/zero, 1 = loss\n///   [3] remaining_lots_hash   - lot state after this proof\n///   [4] initial_lots_hash     - lot state before this proof\n///   [5] price_feed_address\n\nfn main(\n    verification_key: UltraHonkVerificationKey,\n    vkey_hash: Field,\n    proof_left: UltraHonkZKProof,\n    proof_right: Option<UltraHonkZKProof>,\n    public_inputs_left: [Field; 6],\n    public_inputs_right: Option<[Field; 6]>,\n    zero_leaf_hint: Option<Field>,\n    // The expected leaf circuit vkey hash (for level 0 validation)\n    leaf_vkey_hash: Field,\n    // Summary circuit vkey hash - passed through for chaining\n    summary_vkey_hash: Field,\n) -> pub (Field, Field, Field, Field, Field, Field) {\n    // 1. Verify left proof (always present)\n    verify_honk_proof(verification_key, proof_left, public_inputs_left, vkey_hash);\n\n    // 2. Extract values from left proof\n    let left_node = public_inputs_left[0];\n    let left_pnl = public_inputs_left[1];\n    let left_pnl_neg = public_inputs_left[2];\n    let left_remaining_lots = public_inputs_left[3];\n    let left_initial_lots = public_inputs_left[4];\n    let left_price_feed = public_inputs_left[5];\n\n    // 3. Handle right proof (if present) or use zero padding\n    let mut right_node: Field = 0;\n    let mut right_pnl: Field = 0;\n    let mut right_pnl_neg: Field = 0;\n    let mut right_remaining_lots: Field = 0;\n    let mut right_initial_lots: Field = 0;\n\n    if proof_right.is_some() {\n        let right_inputs = public_inputs_right.unwrap();\n        verify_honk_proof(verification_key, proof_right.unwrap(), right_inputs, vkey_hash);\n\n        right_node = right_inputs[0];\n        right_pnl = right_inputs[1];\n        right_pnl_neg = right_inputs[2];\n        right_remaining_lots = right_inputs[3];\n        right_initial_lots = right_inputs[4];\n\n        // Ensure same price feed address\n        assert(right_inputs[5] == left_price_feed, \"price feed address mismatch\");\n\n        // 4. Verify lot hash chain: left's remaining must equal right's initial\n        assert(\n            left_remaining_lots == right_initial_lots,\n            \"lot hash chain broken: left remaining != right initial\",\n        );\n    } else {\n        right_node = zero_leaf_hint.unwrap();\n        // right_pnl stays 0, right_pnl_neg stays 0\n        // For padding: right's initial lots = left's remaining lots (trivial chain)\n        right_remaining_lots = left_remaining_lots;\n        right_initial_lots = left_remaining_lots;\n    }\n\n    // 5. VKey validation based on level\n    // Individual swap proofs don't output a vkey marker. Instead we use a convention:\n    // At level 0 (verifying leaf proofs), we check against leaf_vkey_hash.\n    // At level 1+ (verifying summary proofs), we check against summary_vkey_hash.\n    // The caller passes the appropriate vkey_hash for the level being verified.\n    // We need a way to detect the level. Use: if vkey_hash == leaf_vkey_hash, it's level 0.\n    if vkey_hash == leaf_vkey_hash {\n        // Level 0: verifying individual swap proofs\n        // No additional vkey chain check needed\n    } else {\n        // Level 1+: verifying summary proofs - vkey must match summary_vkey_hash\n        assert(vkey_hash == summary_vkey_hash, \"vkey hash inconsistent with summary_vkey_hash\");\n    }\n\n    // 6. Hash the nodes into merkle root\n    let root = poseidon2_hash([left_node, right_node]);\n\n    // 7. Sum signed PnL using i64\n    let left_pnl_signed: i64 = if left_pnl_neg == 1 {\n        -(left_pnl as i64)\n    } else {\n        left_pnl as i64\n    };\n    let right_pnl_signed: i64 = if right_pnl_neg == 1 {\n        -(right_pnl as i64)\n    } else {\n        right_pnl as i64\n    };\n    let total_pnl_signed: i64 = left_pnl_signed + right_pnl_signed;\n\n    let total_pnl_is_negative: Field = if total_pnl_signed < 0 { 1 } else { 0 };\n    let total_pnl: Field = if total_pnl_signed < 0 {\n        (-total_pnl_signed) as u64 as Field\n    } else {\n        total_pnl_signed as u64 as Field\n    };\n\n    // 8. Output: chain endpoints are left's initial and right's remaining\n    (root, total_pnl, total_pnl_is_negative, right_remaining_lots, left_initial_lots, left_price_feed)\n}\n","path":"/Users/jp4g/Workground/aztec/fde/pnl-proof/circuits/swap_summary_tree/src/main.nr"},"52":{"source":"// Constants for UltraHonk recursive verifier inputs\npub global PROOF_TYPE_HONK: u32 = 0; // identifier for UltraHonk verfier\npub global RECURSIVE_PROOF_LENGTH: u32 = 457;\npub global ULTRA_VK_LENGTH_IN_FIELDS: u32 = 115;\n\npub type UltraHonkProof = [Field; RECURSIVE_PROOF_LENGTH];\npub type UltraHonkVerificationKey = [Field; ULTRA_VK_LENGTH_IN_FIELDS];\n\n// Constants for Rollup-UltraHonk recursive verifier inputs (N.B. this is equivalent to UH plus IPA claim and proof)\npub global PROOF_TYPE_ROLLUP_HONK: u32 = 4; // identifier for rollup-UltraHonk verfier\npub global IPA_CLAIM_SIZE: u32 = 10;\npub global IPA_PROOF_LENGTH: u32 = 64;\npub global RECURSIVE_ROLLUP_HONK_PROOF_LENGTH: u32 =\n    RECURSIVE_PROOF_LENGTH + IPA_CLAIM_SIZE + IPA_PROOF_LENGTH;\n\npub type RollupHonkProof = [Field; RECURSIVE_ROLLUP_HONK_PROOF_LENGTH];\npub type RollupHonkVerificationKey = [Field; ULTRA_VK_LENGTH_IN_FIELDS];\n\npub global PROOF_TYPE_HONK_ZK: u32 = 6; // identifier for UltraHonk ZK verfier\npub global RECURSIVE_ZK_PROOF_LENGTH: u32 = 492 + 16;\n\npub type UltraHonkZKProof = [Field; RECURSIVE_ZK_PROOF_LENGTH];\n\n// Verifies a non-zero-knowledge UltraHonk proof.\n//\n// Represents standard UltraHonk recursive verification for proofs that do not hide the witness.\n// Use this only in situations where zero-knowledge is not required.\npub fn verify_honk_proof_non_zk<let N: u32>(\n    verification_key: UltraHonkVerificationKey,\n    proof: UltraHonkProof,\n    public_inputs: [Field; N],\n    key_hash: Field, // Hash of the verification key\n) {\n    std::verify_proof_with_type(\n        verification_key,\n        proof,\n        public_inputs,\n        key_hash,\n        PROOF_TYPE_HONK,\n    );\n}\n\n// Verifies a non-zero-knowledge Rollup UltraHonk proof with IPA (Inner Product Argument).\n//\n// This variant includes an IPA claim and proof appended to the standard UltraHonk proof,\n// used to amortize IPA recursive verification costs in rollup circuits.\npub fn verify_rolluphonk_proof<let N: u32>(\n    verification_key: RollupHonkVerificationKey,\n    proof: RollupHonkProof,\n    public_inputs: [Field; N],\n    key_hash: Field, // Hash of the verification key\n) {\n    std::verify_proof_with_type(\n        verification_key,\n        proof,\n        public_inputs,\n        key_hash,\n        PROOF_TYPE_ROLLUP_HONK,\n    );\n}\n\n// Verifies a zero-knowledge UltraHonk proof.\n//\n// This verifier is for UltraHonk proofs constructed with zero-knowledge, which hide the witness\n// values from the verifier.\n// Note: We intentionally choose the generic name \"verify_honk_proof\" for this function, as we \n// want ZK to be the default unless the user explicitly opts out.\npub fn verify_honk_proof<let N: u32>(\n    verification_key: UltraHonkVerificationKey,\n    proof: UltraHonkZKProof,\n    public_inputs: [Field; N],\n    key_hash: Field, // Hash of the verification key\n) {\n    std::verify_proof_with_type(\n        verification_key,\n        proof,\n        public_inputs,\n        key_hash,\n        PROOF_TYPE_HONK_ZK,\n    );\n}\n","path":"/Users/jp4g/Workground/aztec/fde/aztec-packages/barretenberg/noir/bb_proof_verification/src/lib.nr"},"140":{"source":"mod poseidon2_chunks;\n\nuse crate::{\n    abis::{\n        contract_class_function_leaf_preimage::ContractClassFunctionLeafPreimage,\n        function_selector::FunctionSelector,\n        note_hash::NoteHash,\n        nullifier::Nullifier,\n        private_log::{PrivateLog, PrivateLogData},\n        transaction::tx_request::TxRequest,\n    },\n    address::{AztecAddress, EthAddress},\n    constants::{\n        CONTRACT_CLASS_LOG_SIZE_IN_FIELDS, FUNCTION_TREE_HEIGHT, GENERATOR_INDEX__NOTE_HASH_NONCE,\n        GENERATOR_INDEX__OUTER_NULLIFIER, GENERATOR_INDEX__SILOED_NOTE_HASH,\n        GENERATOR_INDEX__UNIQUE_NOTE_HASH, NULL_MSG_SENDER_CONTRACT_ADDRESS, TWO_POW_64,\n    },\n    merkle_tree::root_from_sibling_path,\n    messaging::l2_to_l1_message::L2ToL1Message,\n    poseidon2::Poseidon2Sponge,\n    side_effect::{Counted, Scoped},\n    traits::{FromField, Hash, ToField},\n    utils::field::{field_from_bytes, field_from_bytes_32_trunc},\n};\n\npub use poseidon2_chunks::poseidon2_absorb_in_chunks_existing_sponge;\nuse poseidon2_chunks::poseidon2_absorb_in_chunks;\nuse std::embedded_curve_ops::EmbeddedCurveScalar;\n\npub fn sha256_to_field<let N: u32>(bytes_to_hash: [u8; N]) -> Field {\n    let sha256_hashed = sha256::digest(bytes_to_hash);\n    let hash_in_a_field = field_from_bytes_32_trunc(sha256_hashed);\n\n    hash_in_a_field\n}\n\npub fn private_functions_root_from_siblings(\n    selector: FunctionSelector,\n    vk_hash: Field,\n    function_leaf_index: Field,\n    function_leaf_sibling_path: [Field; FUNCTION_TREE_HEIGHT],\n) -> Field {\n    let function_leaf_preimage = ContractClassFunctionLeafPreimage { selector, vk_hash };\n    let function_leaf = function_leaf_preimage.hash();\n    root_from_sibling_path(\n        function_leaf,\n        function_leaf_index,\n        function_leaf_sibling_path,\n    )\n}\n\npub fn compute_note_hash_nonce(first_nullifier_in_tx: Field, note_index_in_tx: u32) -> Field {\n    // Hashing the first nullifier with note index in tx is guaranteed to be unique (because all nullifiers are also\n    // unique).\n    poseidon2_hash_with_separator(\n        [first_nullifier_in_tx, note_index_in_tx as Field],\n        GENERATOR_INDEX__NOTE_HASH_NONCE,\n    )\n}\n\npub fn compute_unique_note_hash(note_nonce: Field, siloed_note_hash: Field) -> Field {\n    let inputs = [note_nonce, siloed_note_hash];\n    poseidon2_hash_with_separator(inputs, GENERATOR_INDEX__UNIQUE_NOTE_HASH)\n}\n\npub fn compute_nonce_and_unique_note_hash(\n    siloed_note_hash: Field,\n    first_nullifier: Field,\n    note_index_in_tx: u32,\n) -> Field {\n    let note_nonce = compute_note_hash_nonce(first_nullifier, note_index_in_tx);\n    compute_unique_note_hash(note_nonce, siloed_note_hash)\n}\n\npub fn compute_siloed_note_hash(app: AztecAddress, note_hash: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [app.to_field(), note_hash],\n        GENERATOR_INDEX__SILOED_NOTE_HASH,\n    )\n}\n\n/// Computes unique note hashes from siloed note hashes\npub fn compute_unique_siloed_note_hash(\n    siloed_note_hash: Field,\n    first_nullifier: Field,\n    note_index_in_tx: u32,\n) -> Field {\n    if siloed_note_hash == 0 {\n        0\n    } else {\n        compute_nonce_and_unique_note_hash(siloed_note_hash, first_nullifier, note_index_in_tx)\n    }\n}\n\n/// Siloing in the context of Aztec refers to the process of hashing a note hash with a contract address (this way\n/// the note hash is scoped to a specific contract). This is used to prevent intermingling of notes between contracts.\npub fn silo_note_hash(note_hash: Scoped<Counted<NoteHash>>) -> Field {\n    if note_hash.contract_address.is_zero() {\n        0\n    } else {\n        compute_siloed_note_hash(note_hash.contract_address, note_hash.innermost())\n    }\n}\n\npub fn compute_siloed_nullifier(app: AztecAddress, nullifier: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [app.to_field(), nullifier],\n        GENERATOR_INDEX__OUTER_NULLIFIER,\n    )\n}\n\npub fn silo_nullifier(nullifier: Scoped<Counted<Nullifier>>) -> Field {\n    let value = nullifier.innermost().value;\n    // Q: shouldn't we be checking whether the _whole_ nullifier is empty?\n    // A: We don't have to. The init and inner circuits add contract address to non-empty nullifiers.\n    // So we know we should silo it if the contract address is not empty.\n    if nullifier.contract_address.is_zero() {\n        value // Return `value` instead of 0 because an already-siloed nullifier's contract address is zero.\n    } else {\n        compute_siloed_nullifier(nullifier.contract_address, value)\n    }\n}\n\npub fn create_protocol_nullifier(tx_request: TxRequest) -> Scoped<Counted<Nullifier>> {\n    Nullifier { value: tx_request.hash(), note_hash: 0 }.count(1).scope(\n        NULL_MSG_SENDER_CONTRACT_ADDRESS,\n    )\n}\n\npub fn compute_siloed_private_log_field(contract_address: AztecAddress, field: Field) -> Field {\n    poseidon2_hash([contract_address.to_field(), field])\n}\n\npub fn silo_private_log(private_log: Scoped<Counted<PrivateLogData>>) -> PrivateLog {\n    let log = private_log.innermost().log;\n    if private_log.contract_address.is_zero() {\n        log\n    } else {\n        let mut fields = log.fields;\n        fields[0] = compute_siloed_private_log_field(private_log.contract_address, fields[0]);\n        PrivateLog::new(fields, log.length)\n    }\n}\n\npub fn compute_contract_class_log_hash(log: [Field; CONTRACT_CLASS_LOG_SIZE_IN_FIELDS]) -> Field {\n    poseidon2_hash(log)\n}\n\npub fn compute_app_secret_key(\n    master_secret_key: EmbeddedCurveScalar,\n    app_address: AztecAddress,\n    app_secret_generator: Field,\n) -> Field {\n    poseidon2_hash_with_separator(\n        [master_secret_key.hi, master_secret_key.lo, app_address.to_field()],\n        app_secret_generator,\n    )\n}\n\npub fn merkle_hash(left: Field, right: Field) -> Field {\n    poseidon2_hash([left, right])\n}\n\npub fn compute_l2_to_l1_hash(\n    contract_address: AztecAddress,\n    recipient: EthAddress,\n    content: Field,\n    rollup_version_id: Field,\n    chain_id: Field,\n) -> Field {\n    let contract_address_bytes: [u8; 32] = contract_address.to_field().to_be_bytes();\n    let recipient_bytes: [u8; 20] = recipient.to_be_bytes();\n    let content_bytes: [u8; 32] = content.to_be_bytes();\n    let rollup_version_id_bytes: [u8; 32] = rollup_version_id.to_be_bytes();\n    let chain_id_bytes: [u8; 32] = chain_id.to_be_bytes();\n\n    let mut bytes: [u8; 148] = std::mem::zeroed();\n    for i in 0..32 {\n        bytes[i] = contract_address_bytes[i];\n        bytes[i + 32] = rollup_version_id_bytes[i];\n        // 64 - 84 are for recipient.\n        bytes[i + 84] = chain_id_bytes[i];\n        bytes[i + 116] = content_bytes[i];\n    }\n\n    for i in 0..20 {\n        bytes[64 + i] = recipient_bytes[i];\n    }\n\n    sha256_to_field(bytes)\n}\n\npub fn silo_l2_to_l1_message(\n    msg: Scoped<L2ToL1Message>,\n    rollup_version_id: Field,\n    chain_id: Field,\n) -> Field {\n    if msg.contract_address.is_zero() {\n        0\n    } else {\n        compute_l2_to_l1_hash(\n            msg.contract_address,\n            msg.inner.recipient,\n            msg.inner.content,\n            rollup_version_id,\n            chain_id,\n        )\n    }\n}\n\n/// Computes sha256 hash of 2 input fields.\n///\n/// @returns A truncated field (i.e., the first byte is always 0).\npub fn accumulate_sha256(v0: Field, v1: Field) -> Field {\n    // Concatenate two fields into 32 x 2 = 64 bytes\n    let v0_as_bytes: [u8; 32] = v0.to_be_bytes();\n    let v1_as_bytes: [u8; 32] = v1.to_be_bytes();\n    let hash_input_flattened = v0_as_bytes.concat(v1_as_bytes);\n\n    sha256_to_field(hash_input_flattened)\n}\n\n#[inline_always]\npub fn pedersen_hash<let N: u32>(inputs: [Field; N], hash_index: u32) -> Field {\n    std::hash::pedersen_hash_with_separator(inputs, hash_index)\n}\n\npub fn poseidon2_hash<let N: u32>(inputs: [Field; N]) -> Field {\n    poseidon::poseidon2::Poseidon2::hash(inputs, N)\n}\n\n#[no_predicates]\npub fn poseidon2_hash_with_separator<let N: u32, T>(inputs: [Field; N], separator: T) -> Field\nwhere\n    T: ToField,\n{\n    let inputs_with_separator = [separator.to_field()].concat(inputs);\n    poseidon2_hash(inputs_with_separator)\n}\n\n/// Computes a Poseidon2 hash over a dynamic-length subarray of the given input.\n/// Only the first `in_len` fields of `input` are absorbed; any remaining fields are ignored.\n/// The caller is responsible for ensuring that the input is padded with zeros if required.\n#[no_predicates]\npub fn poseidon2_hash_subarray<let N: u32>(input: [Field; N], in_len: u32) -> Field {\n    let mut sponge = poseidon2_absorb_in_chunks(input, in_len);\n    sponge.squeeze()\n}\n\n// NB the below is the same as poseidon::poseidon2::Poseidon2::hash(), but replacing a range check with a bit check,\n// and absorbing in chunks of 3 below.\n#[no_predicates]\npub fn poseidon2_cheaper_variable_hash<let N: u32>(input: [Field; N], in_len: u32) -> Field {\n    let mut sponge = poseidon2_absorb_in_chunks(input, in_len);\n    // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n    // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n    // fixed-length and variable-length hashes do not collide)\n    if in_len != N {\n        sponge.absorb(1);\n    }\n    sponge.squeeze()\n}\n\n// This function is  unconstrained because it is intended to be used in unconstrained context only as\n// in constrained contexts it would be too inefficient.\npub unconstrained fn poseidon2_hash_with_separator_bounded_vec<let N: u32, T>(\n    inputs: BoundedVec<Field, N>,\n    separator: T,\n) -> Field\nwhere\n    T: ToField,\n{\n    let in_len = inputs.len() + 1;\n    let iv: Field = (in_len as Field) * TWO_POW_64;\n    let mut sponge = Poseidon2Sponge::new(iv);\n    sponge.absorb(separator.to_field());\n\n    for i in 0..inputs.len() {\n        sponge.absorb(inputs.get(i));\n    }\n\n    sponge.squeeze()\n}\n\n#[no_predicates]\npub fn poseidon2_hash_bytes<let N: u32>(inputs: [u8; N]) -> Field {\n    let mut fields = [0; (N + 30) / 31];\n    let mut field_index = 0;\n    let mut current_field = [0; 31];\n    for i in 0..inputs.len() {\n        let index = i % 31;\n        current_field[index] = inputs[i];\n        if index == 30 {\n            fields[field_index] = field_from_bytes(current_field, false);\n            current_field = [0; 31];\n            field_index += 1;\n        }\n    }\n    if field_index != fields.len() {\n        fields[field_index] = field_from_bytes(current_field, false);\n    }\n    poseidon2_hash(fields)\n}\n\n#[test]\nfn poseidon_chunks_matches_fixed() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut fixed_input = [3; 501];\n    assert(in_len == fixed_input.len()); // sanity check\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    let sub_chunk_hash = poseidon2_hash_subarray(input, in_len);\n    let fixed_len_hash = poseidon::poseidon2::Poseidon2::hash(fixed_input, fixed_input.len());\n    assert(sub_chunk_hash == fixed_len_hash);\n}\n\n#[test]\nfn poseidon_chunks_matches_variable() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    let variable_chunk_hash = poseidon2_cheaper_variable_hash(input, in_len);\n    let variable_len_hash = poseidon::poseidon2::Poseidon2::hash(input, in_len);\n    assert(variable_chunk_hash == variable_len_hash);\n}\n\n#[test]\nfn smoke_sha256_to_field() {\n    let full_buffer = [\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n        25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n        48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n        71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93,\n        94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n        149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n    ];\n    let result = sha256_to_field(full_buffer);\n\n    assert(result == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184c7);\n\n    // to show correctness of the current ver (truncate one byte) vs old ver (mod full bytes):\n    let result_bytes = sha256::digest(full_buffer);\n    let truncated_field = crate::utils::field::field_from_bytes_32_trunc(result_bytes);\n    assert(truncated_field == result);\n    let mod_res = result + (result_bytes[31] as Field);\n    assert(mod_res == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184e0);\n}\n\n#[test]\nfn compute_l2_l1_hash() {\n    // All zeroes\n    let hash_result =\n        compute_l2_to_l1_hash(AztecAddress::from_field(0), EthAddress::zero(), 0, 0, 0);\n    assert(hash_result == 0x3b18c58c739716e76429634a61375c45b3b5cd470c22ab6d3e14cee23dd992);\n\n    // Non-zero case\n    let hash_result = compute_l2_to_l1_hash(\n        AztecAddress::from_field(1),\n        EthAddress::from_field(3),\n        5,\n        2,\n        4,\n    );\n    assert(hash_result == 0xaab2a5828156782b12a1dc6f336e2bc627eb1b9514b02d511f66296990c050);\n}\n\n#[test]\nfn silo_l2_to_l1_message_matches_typescript() {\n    let version = 4;\n    let chainId = 5;\n\n    let hash = silo_l2_to_l1_message(\n        L2ToL1Message { recipient: EthAddress::from_field(1), content: 2 }.scope(\n            AztecAddress::from_field(3),\n        ),\n        version,\n        chainId,\n    );\n\n    // The following value was generated by `yarn-project/stdlib/src/hash/hash.test.ts`\n    let hash_from_typescript = 0x0081edf209e087ad31b3fd24263698723d57190bd1d6e9fe056fc0c0a68ee661;\n\n    assert_eq(hash, hash_from_typescript);\n}\n\n#[test]\nunconstrained fn poseidon2_hash_with_separator_bounded_vec_matches_non_bounded_vec_version() {\n    let inputs = BoundedVec::<Field, 4>::from_array([1, 2, 3]);\n    let separator = 42;\n\n    // Hash using bounded vec version\n    let bounded_result = poseidon2_hash_with_separator_bounded_vec(inputs, separator);\n\n    // Hash using regular version\n    let regular_result = poseidon2_hash_with_separator([1, 2, 3], separator);\n\n    // Results should match\n    assert_eq(bounded_result, regular_result);\n}\n","path":"/Users/jp4g/Workground/aztec/fde/aztec-packages/noir-projects/noir-protocol-circuits/crates/types/src/hash.nr"},"205":{"source":"use std::default::Default;\nuse std::hash::Hasher;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field; 3],\n    state: [Field; 4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        Poseidon2::hash_internal(input, message_size, message_size != N)\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result =\n            Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(\n        input: [Field; N],\n        in_len: u32,\n        is_variable_length: bool,\n    ) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv: Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher {\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv: Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n","path":"/Users/jp4g/nargo/github.com/noir-lang/poseidon/v0.1.1/src/poseidon2.nr"}},"expression_width":{"Bounded":{"width":4}}}